{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4dcc783-3758-4f78-826d-6a9cfca0ec59",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439c6d03-23ca-4b0e-8844-b4a30e7bd765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:57:56.590237Z",
     "iopub.status.busy": "2024-06-15T07:57:56.589540Z",
     "iopub.status.idle": "2024-06-15T07:58:00.277785Z",
     "shell.execute_reply": "2024-06-15T07:58:00.276589Z",
     "shell.execute_reply.started": "2024-06-15T07:57:56.590203Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import d2l_torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40da082f-cbd4-4014-bf04-398058ca49fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.837189Z",
     "iopub.status.busy": "2024-06-15T07:58:00.836785Z",
     "iopub.status.idle": "2024-06-15T07:58:00.842071Z",
     "shell.execute_reply": "2024-06-15T07:58:00.841098Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.837168Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基于位置的前馈网络\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb52bfe2-b1ea-46d5-86fe-4269e19f70e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.844915Z",
     "iopub.status.busy": "2024-06-15T07:58:00.844440Z",
     "iopub.status.idle": "2024-06-15T07:58:00.853301Z",
     "shell.execute_reply": "2024-06-15T07:58:00.852792Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.844885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0984, -0.1298, -0.1495,  0.3052,  0.0069, -0.1255,  0.3295, -0.4647],\n",
       "        [ 0.0984, -0.1298, -0.1495,  0.3052,  0.0069, -0.1255,  0.3295, -0.4647],\n",
       "        [ 0.0984, -0.1298, -0.1495,  0.3052,  0.0069, -0.1255,  0.3295, -0.4647]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2, 3, 4)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf430b87-8825-48fb-b34c-46b8e3195510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.854624Z",
     "iopub.status.busy": "2024-06-15T07:58:00.854364Z",
     "iopub.status.idle": "2024-06-15T07:58:00.858431Z",
     "shell.execute_reply": "2024-06-15T07:58:00.857690Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.854604Z"
    }
   },
   "outputs": [],
   "source": [
    "# ffn(torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aca8836-b4ab-4a7d-b3fc-a96f8989b5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.859674Z",
     "iopub.status.busy": "2024-06-15T07:58:00.859409Z",
     "iopub.status.idle": "2024-06-15T07:58:00.862433Z",
     "shell.execute_reply": "2024-06-15T07:58:00.861660Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.859652Z"
    }
   },
   "outputs": [],
   "source": [
    "# ffn(torch.ones((2, 3, 4)))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e246479d-2da5-4826-8767-74d129a7e595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.863797Z",
     "iopub.status.busy": "2024-06-15T07:58:00.863530Z",
     "iopub.status.idle": "2024-06-15T07:58:00.867565Z",
     "shell.execute_reply": "2024-06-15T07:58:00.866488Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.863776Z"
    }
   },
   "outputs": [],
   "source": [
    "# 残差连接和层规范化\n",
    "# 层规范化是基于特征维度进行规范化\n",
    "# 批量规范化通常不如层规范化效果好\n",
    "\n",
    "# ln = nn.LayerNorm(2)\n",
    "# bn = nn.BatchNorm1d(2)\n",
    "# X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
    "# print('layer norm:', ln(X), '\\nbatch norm:', bn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d050d7ec-3503-4e22-abd7-24d726a1f6d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.870182Z",
     "iopub.status.busy": "2024-06-15T07:58:00.869355Z",
     "iopub.status.idle": "2024-06-15T07:58:00.876883Z",
     "shell.execute_reply": "2024-06-15T07:58:00.875899Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.870138Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226576af-849a-4f7d-ae8b-2e45fe9004c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.878386Z",
     "iopub.status.busy": "2024-06-15T07:58:00.878133Z",
     "iopub.status.idle": "2024-06-15T07:58:00.881991Z",
     "shell.execute_reply": "2024-06-15T07:58:00.881188Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.878364Z"
    }
   },
   "outputs": [],
   "source": [
    "# add_norm = AddNorm([3, 4], 0.5)\n",
    "# add_norm.eval()\n",
    "# add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72752989-fbfc-4242-8a39-61e08706c270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.889857Z",
     "iopub.status.busy": "2024-06-15T07:58:00.888925Z",
     "iopub.status.idle": "2024-06-15T07:58:00.895702Z",
     "shell.execute_reply": "2024-06-15T07:58:00.894848Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.889826Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3119947f-a6bc-4962-9cba-4a8783f4661b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.897126Z",
     "iopub.status.busy": "2024-06-15T07:58:00.896758Z",
     "iopub.status.idle": "2024-06-15T07:58:00.904305Z",
     "shell.execute_reply": "2024-06-15T07:58:00.903265Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.897104Z"
    }
   },
   "outputs": [],
   "source": [
    "def transpose_qkv(X, num_heads):\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d3c4b0-0361-438d-bea5-6e41c7cb6bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.906684Z",
     "iopub.status.busy": "2024-06-15T07:58:00.905982Z",
     "iopub.status.idle": "2024-06-15T07:58:00.911481Z",
     "shell.execute_reply": "2024-06-15T07:58:00.910727Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.906639Z"
    }
   },
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc01ca1-ac2b-47d8-ac74-3944408a2e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.912898Z",
     "iopub.status.busy": "2024-06-15T07:58:00.912604Z",
     "iopub.status.idle": "2024-06-15T07:58:00.920430Z",
     "shell.execute_reply": "2024-06-15T07:58:00.919506Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.912868Z"
    }
   },
   "outputs": [],
   "source": [
    "# 编码器\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8bdfee-d820-4bd8-b6d0-095b41beec9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.922143Z",
     "iopub.status.busy": "2024-06-15T07:58:00.921769Z",
     "iopub.status.idle": "2024-06-15T07:58:00.928936Z",
     "shell.execute_reply": "2024-06-15T07:58:00.928228Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.922099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderBlock(\n",
       "  (attention): MultiHeadAttention(\n",
       "    (attention): DotProductAttention(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W_q): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_k): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_v): Linear(in_features=24, out_features=24, bias=False)\n",
       "    (W_o): Linear(in_features=24, out_features=24, bias=False)\n",
       "  )\n",
       "  (addnorm1): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (ffn): PositionWiseFFN(\n",
       "    (dense1): Linear(in_features=24, out_features=48, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dense2): Linear(in_features=48, out_features=24, bias=True)\n",
       "  )\n",
       "  (addnorm2): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((100, 24), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "# encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae5001a-f548-49f8-9521-51db948644c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.931753Z",
     "iopub.status.busy": "2024-06-15T07:58:00.930995Z",
     "iopub.status.idle": "2024-06-15T07:58:00.939563Z",
     "shell.execute_reply": "2024-06-15T07:58:00.938845Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.931695Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(d2l.Encoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                                 EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                                              norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                                              num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000aaba6-0947-4e5e-976a-ee727553fd67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.940849Z",
     "iopub.status.busy": "2024-06-15T07:58:00.940495Z",
     "iopub.status.idle": "2024-06-15T07:58:00.948361Z",
     "shell.execute_reply": "2024-06-15T07:58:00.945174Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.940824Z"
    }
   },
   "outputs": [],
   "source": [
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec718107-f28b-485d-bcdf-c97e96f39af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.950373Z",
     "iopub.status.busy": "2024-06-15T07:58:00.949708Z",
     "iopub.status.idle": "2024-06-15T07:58:00.954347Z",
     "shell.execute_reply": "2024-06-15T07:58:00.953595Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.950342Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder = TransformerEncoder(\n",
    "#     200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "# encoder.eval()\n",
    "# encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96697898-249b-4055-8c2d-6f1234a73449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.955958Z",
     "iopub.status.busy": "2024-06-15T07:58:00.955668Z",
     "iopub.status.idle": "2024-06-15T07:58:00.963125Z",
     "shell.execute_reply": "2024-06-15T07:58:00.962228Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.955936Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        \n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3343c1-473c-4f67-af2c-f8bb25c88eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.966901Z",
     "iopub.status.busy": "2024-06-15T07:58:00.965926Z",
     "iopub.status.idle": "2024-06-15T07:58:00.974669Z",
     "shell.execute_reply": "2024-06-15T07:58:00.973801Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.966859Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
    "decoder_blk.eval()\n",
    "X = torch.ones((2, 100, 24))\n",
    "# state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "# decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d33d5121-1e36-470c-b20f-01677b6cec54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.976124Z",
     "iopub.status.busy": "2024-06-15T07:58:00.975630Z",
     "iopub.status.idle": "2024-06-15T07:58:00.980234Z",
     "shell.execute_reply": "2024-06-15T07:58:00.979251Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.976103Z"
    }
   },
   "outputs": [],
   "source": [
    "# 带有注意力机制的解码器\n",
    "class AttentionDecoder(d2l.Decoder):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd17525f-c554-4b53-bcf2-ee2436b15985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.983168Z",
     "iopub.status.busy": "2024-06-15T07:58:00.982749Z",
     "iopub.status.idle": "2024-06-15T07:58:00.991642Z",
     "shell.execute_reply": "2024-06-15T07:58:00.990636Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.983137Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                                 DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                                              norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                                              num_heads, dropout, i))\n",
    "            self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    \n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * len(self.blks)]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range(2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff99ed25-268b-4fa8-886c-0795c05355cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:00.993313Z",
     "iopub.status.busy": "2024-06-15T07:58:00.992916Z",
     "iopub.status.idle": "2024-06-15T07:58:00.999101Z",
     "shell.execute_reply": "2024-06-15T07:58:00.997226Z",
     "shell.execute_reply.started": "2024-06-15T07:58:00.993292Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6628644e-f038-4dd4-b486-ae1f402b231b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:01.001747Z",
     "iopub.status.busy": "2024-06-15T07:58:01.001214Z",
     "iopub.status.idle": "2024-06-15T07:58:01.010365Z",
     "shell.execute_reply": "2024-06-15T07:58:01.009703Z",
     "shell.execute_reply.started": "2024-06-15T07:58:01.001703Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_voccab, device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if 'weight' in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "          f'tokens/src on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04dc3fd2-0b7a-4b5c-8861-848760bb8489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:01.011991Z",
     "iopub.status.busy": "2024-06-15T07:58:01.011249Z",
     "iopub.status.idle": "2024-06-15T07:58:01.018306Z",
     "shell.execute_reply": "2024-06-15T07:58:01.017452Z",
     "shell.execute_reply.started": "2024-06-15T07:58:01.011950Z"
    }
   },
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction = 'none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c015ca6-6c66-432d-96c3-f06f632c129d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:01.020056Z",
     "iopub.status.busy": "2024-06-15T07:58:01.019467Z",
     "iopub.status.idle": "2024-06-15T07:58:01.024444Z",
     "shell.execute_reply": "2024-06-15T07:58:01.023495Z",
     "shell.execute_reply.started": "2024-06-15T07:58:01.020026Z"
    }
   },
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd658f93-ae34-4b70-ba61-cb7a77925ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T07:58:01.026284Z",
     "iopub.status.busy": "2024-06-15T07:58:01.025961Z",
     "iopub.status.idle": "2024-06-15T07:58:04.966186Z",
     "shell.execute_reply": "2024-06-15T07:58:04.965388Z",
     "shell.execute_reply.started": "2024-06-15T07:58:01.026255Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb5ce8-3cc4-4e11-ba84-6a8c5674a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = ['go .', 'i lost .', 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation},',\n",
    "          f'bleu {d2l.bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926289dd-0610-4fa3-a165-52468c39a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化编码器的注意力权重\n",
    "enc_attention_weights = torch.cat(net.encoder.attention_weights, 0).reshape((num_layers, num_heads,\n",
    "                                                                             -1, num_steps))\n",
    "enc_attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903ecb7-4b93-41f4-bda2-52ba487fdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.show_heatmaps(\n",
    "    enc_attention_weights,cpu(), xlabel='Key positions',\n",
    "    ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],\n",
    "    figsize=(7, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124235c8-a2e5-43ec-95b7-1cb8010a22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_attention_weights_2d = [head[0].tolist()\n",
    "                            for step in dec_attention_weight_seq\n",
    "                            for attn in step for blk in attn for head in blk]\n",
    "dec_attention_weights_filled = torch.tensor(\n",
    "    pd.DataFrame(dec_attention_weights_2d).fillna(0.0).values)\n",
    "dec_attention_weights = dec_attention_weights_filled.reshape((-1, 2, num_layers, num_heads, num_steps))\n",
    "dec_self_attention_weights, dec_inter_attention_weights = \\\n",
    "    dec_attention_weights.permute(1, 2, 3, 0, 4)\n",
    "dec_self_attention_weights.shape, dec_inter_attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a8b20-09df-4b0c-a6c3-ed3787a27b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.show_heatmaps(\n",
    "    dec_self_attention_weights[:, :, :, :len(translation.split()) + 1],\n",
    "    xlabel='Key positions', ylabel='Query positions',\n",
    "    titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb44911-60c3-4b5c-841a-3af65b7b825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.show_heatmaps(\n",
    "    dec_inter_attention_weights, xlabel='Key positions',\n",
    "    ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],\n",
    "    figsize=(7, 3.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
